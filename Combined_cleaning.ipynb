{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers(df,threshold=3.5, method='mahalanobis'):\n",
    "    \"\"\"Applies outlier detection techqniue based on the specified method and removes it\n",
    "    Parameters\n",
    "    -----------\n",
    "    df: pandas.DataFrame\n",
    "        Dataframe on which the outliers to be detected and removed\n",
    "    threshold: float,optional\n",
    "        Threshold value to be used when method is Zscore\n",
    "    method: str\n",
    "        Specifies the method to be used for outlier detection\n",
    "    Returns\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Returns the outlier treated data frame\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "    import numpy as np\n",
    "    df_temp = df.select_dtypes('float64')\n",
    "    if method == 'mahalanobis':\n",
    "        from sklearn.covariance import EllipticEnvelope\n",
    "        clf =EllipticEnvelope(random_state=14)\n",
    "        clf.fit(df.select_dtypes('float64'))\n",
    "        predictions = np.array(clf.predict(df.select_dtypes('float64')))\n",
    "        # find the index where there are outliers. outliers are labeled as -1 and inliers as 1\n",
    "        row_num=np.where(predictions==-1)\n",
    "        id = df.iloc[row_num]['id']\n",
    "        df_outlier = df[~df['id'].isin(id)]\n",
    "    return df_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the descriptors\n",
    "df_study2 = pd.read_csv('datasets/files_generated/study2_cleandata.csv').rename(columns={'Size':'Cond'})\n",
    "df_study1 = pd.read_csv('datasets/files_generated/study1_cleandata.csv')\n",
    "df = pd.concat([df_study1,df_study2])\n",
    "# save the combined studies\n",
    "df.to_csv('datasets/files_generated/combined_cleandata.csv')\n",
    "\n",
    "\n",
    "# treat the combined studies dataframe for outlier detection using Mahalanobis technique\n",
    "df = reject_outliers(df)\n",
    "\n",
    "# save the outlier detected combined dataframe\n",
    "df.to_csv('datasets/files_generated/combined_cleandata_out_mahalanobis.csv')\n",
    "\n",
    "# combine the ratings\n",
    "df_ux2 = pd.read_csv('datasets/rawData.firstTry/UXRatings_study2.csv',index_col=0).rename(\n",
    "    columns={'UserId':'user_id','IconSize':'Cond'}).drop(['Session'],axis=1)[['sessionNr','user_id','PQ', 'ATT', 'HQI', 'HQS', 'HQ','Cond']]\n",
    "df_ux1 = pd.read_csv('datasets/rawData.firstTry/UXRatings_study1.csv',index_col=0)[['sessionNr','user_id','PQ', 'ATT', 'HQI', 'HQS', 'HQ','Cond']]\n",
    "ux = pd.concat([df_ux1,df_ux2])\n",
    "# save the combined ux ratings\n",
    "ux.to_csv('datasets/files_generated/UXRatings_combined.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
