{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Script to run the ML algorithms on the reduced dimensions generated by PCA for STUDY1 and test on STUDY2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "LOG_FILENAME = 'UX_Ratings_PCA.log'\n",
    "logging.basicConfig(filename=LOG_FILENAME,level=logging.INFO)\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import KFold,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from RegscorePy.aic import aic # for calculating Akaikeâ€™s Information Criterion\n",
    "from RegscorePy.bic import bic # for calculating Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataFromCsv(file):\n",
    "    import pandas as pd\n",
    "    print (\"Reading the file from: \",file)\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "def loadDataset(data='study1',path='../datasets/files_generated/UX/study1_features_data.csv',target='PQ',app='Spell'):    \n",
    "#     if data== 'study1':\n",
    "    df = readDataFromCsv(path)\n",
    "#     if data=='study2':\n",
    "#         df = readDataFromCsv(path)\n",
    "    df=df[df['App']==app]   \n",
    "    print('The shape of the data  currently: ',df.shape)\n",
    "    \n",
    "    ## This should not have been there\n",
    "    if(df.isnull().values.any()==True and data=='study1'):\n",
    "        df = df.dropna()\n",
    "        print('The shape of the data after dropping null values: ',df.shape)\n",
    "    if data == 'startData':\n",
    "#         df_join= pd.merge(df_stat_summ_withoutna, df_ux, on=['user_id','App','Cond','sessionNr'])\n",
    "        X,y= df.drop(['PQ', 'ATT', 'HQI', 'HQS', 'HQ'],axis=1),df[target]\n",
    "    elif data=='study1':\n",
    "#         df_join= pd.merge(df_stat_summ_withoutna, df_ux, on=['user_id','App','Cond','sessionNr'])\n",
    "        X,y= df.drop(['user_id','App','Cond','sessionNr','SEA', 'PQ', 'ATT', 'HQI', 'HQS', 'HQ'],axis=1),df[target]\n",
    "    elif data=='study2':\n",
    "#         df_join= pd.merge(df_stat_summ_withoutna, df_ux, how='inner',left_on=['user_id','Cond','sessionNr'],\n",
    "#                            right_on=['UserId','IconSize','Session'])\n",
    "        X,y=df.drop(['sessionNr','App','user_id','Size','UserId', 'Session', \n",
    "                     'PQ', 'ATT', 'HQI', 'HQS', 'HQ', 'IconSize'],axis=1),df[target]\n",
    "        print(X.shape)\n",
    "#     print('shape after join: ',df_join.shape)\n",
    "    df_result={'data':X,'target':y}\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=['../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv']\n",
    "# target='PQ'\n",
    "# data='study2'\n",
    "# dd = loadDataset(path=path[0],target=target,data=data)\n",
    "# X = dd.get('data')\n",
    "# y = dd.get('target')\n",
    "\n",
    "\n",
    "# print(\"shape:\",X.shape)\n",
    "\n",
    "# # remove 0 variance\n",
    "# col_index = np.where(X.var()!=0)\n",
    "# columns = X.loc[:, X.var()== 0.0].columns.values\n",
    "# X = X.loc[:, X.var() != 0.0]\n",
    "\n",
    "# not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "# if data =='study1':\n",
    "#     normality_test_features_path= 'Tables/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# else:\n",
    "#     normality_test_features_path ='Tables/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# print(\"reading the normal features from path: \",normality_test_features_path)\n",
    "# mahalanobis = pd.read_csv(normality_test_features_path)\n",
    "# mahalanobis = list(mahalanobis[mahalanobis['Normality']==True]['Features'].values)\n",
    "# for col in not_columns:\n",
    "#     if(col in mahalanobis):\n",
    "#         mahalanobis.remove(col)\n",
    "\n",
    "# # X=X[mahalanobis]\n",
    "\n",
    "# # Create correlation matrix\n",
    "# corr_matrix = X.corr().abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper_traingle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop_cols = [column for column in upper_traingle.columns if any(upper_traingle[column] >= 0.80)]\n",
    "\n",
    "# # Drop features \n",
    "# X = X.drop(X[to_drop_cols], axis=1)\n",
    "# print(\"current shape:\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normality_test_features_path= 'Tables/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# mahalanobis_study1 = pd.read_csv(normality_test_features_path)\n",
    "# mahalanobis_study1 = list(mahalanobis_study1[mahalanobis_study1['Normality']==True]['Features'].values)\n",
    "# not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "# for col in not_columns:\n",
    "#     if(col in mahalanobis_study1):\n",
    "#         mahalanobis_study1.remove(col)\n",
    "\n",
    "# normality_test_features_path= 'Tables/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# mahalanobis_study2 = pd.read_csv(normality_test_features_path)\n",
    "# mahalanobis_study2 = list(mahalanobis_study2[mahalanobis_study2['Normality']==True]['Features'].values)\n",
    "# not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "# for col in not_columns:\n",
    "#     if(col in mahalanobis_study2):\n",
    "#         mahalanobis_study2.remove(col)\n",
    "        \n",
    "# set1=set(mahalanobis_study1)\n",
    "# set2=set(mahalanobis_study2)\n",
    "\n",
    "# missing = list(sorted(set1 - set2))\n",
    "# added = list(sorted(set2 - set1))\n",
    "\n",
    "# print('missing:', missing)\n",
    "# print('added:', added)\n",
    "# print(len(mahalanobis_study1))\n",
    "# print(len(mahalanobis_study2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalModelSelection(model,param_grid,X,y,method='grid'):\n",
    "    '''Tune the hyperparameters to find the best score personality data'''\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "    from sklearn.pipeline import make_pipeline,Pipeline\n",
    "    from sklearn.model_selection import KFold,GridSearchCV,RandomizedSearchCV\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "#     K = 10\n",
    "#     kf = KFold(n_splits=K, shuffle=True,random_state=32)\n",
    "    \n",
    "    scoring={'r2':'r2','mse':'neg_mean_squared_error','mae':'neg_mean_absolute_error'}\n",
    "#     pca = PCA(random_state=32,svd_solver='full')\n",
    "#     pipe = Pipeline([('scl', StandardScaler()),\n",
    "#                      ('pca',pca),\n",
    "#                     ('clf', model)])\n",
    "    if(method=='grid'):\n",
    "        search = GridSearchCV(model, param_grid, cv=10,n_jobs=-1,scoring=scoring,return_train_score=True,refit='r2')\n",
    "        search.fit(X,y)\n",
    "    if(method=='random'):\n",
    "        search=RandomizedSearchCV(estimator = model, param_distributions = param_grid, \n",
    "                               n_iter = 100, cv = 10, verbose=1, \n",
    "                               random_state=32, n_jobs = -1,scoring=scoring,return_train_score=True,refit='r2')\n",
    "        search.fit(X,y)\n",
    "    \n",
    "#     logging.info('Reduced dimension for 98% variance: {}'.format(search.best_estimator_.named_steps['pca'].components_.shape))\n",
    "#     logging.info('Reduced dimension: {}'.format(search.best_estimator_.named_steps['pca'].n_components_))\n",
    "    \n",
    "    print('Best params: {}'.format(search.best_params_))\n",
    "    logging.info('Best params: {}'.format(search.best_params_))\n",
    "#     print('Best score after fitting the estimator with best params:{}'.format(search.best_score_))\n",
    "#     logging.info('Best score after fitting the estimator with best params:{}'.format(search.best_score_))\n",
    "    print('RMSE: %0.2f'%(np.sqrt(-search.cv_results_['mean_test_mse'][search.best_index_])))\n",
    "    print(\"R2(Validation): %0.2f (+/- %0.2f)\" % (search.best_score_,search.cv_results_['std_test_r2'][search.best_index_]))\n",
    "    print(\"R2(Train): %0.2f (+/- %0.2f)\" % (search.cv_results_['mean_train_r2'][search.best_index_],\n",
    "                                                 search.cv_results_['std_train_r2'][search.best_index_]))\n",
    "    print(\"MAE(Validation): %0.2f (+/- %0.2f)\" % (-search.cv_results_['mean_test_mae'][search.best_index_],\n",
    "                                                  search.cv_results_['std_test_mae'][search.best_index_]))\n",
    "    print(\"MAE(Train): %0.2f (+/- %0.2f)\" % (-search.cv_results_['mean_train_mae'][search.best_index_],\n",
    "                                                 search.cv_results_['std_train_mae'][search.best_index_]))\n",
    "    \n",
    "    logging.info('RMSE: %0.2f'%(np.sqrt(-search.cv_results_['mean_test_mse'][search.best_index_])))\n",
    "    logging.info(\"R2: %0.2f (+/- %0.2f)\" % (search.best_score_,search.cv_results_['std_test_r2'][search.best_index_]))\n",
    "    return search.best_estimator_,search.best_params_, search.best_score_,search.cv_results_,search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_evaluation(pathsArr,model,param_grid,method='grid',data='study1',transformation=False,n_components=0.95):\n",
    "    \n",
    "    if transformation==False:\n",
    "#         pathsArr=['../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "        targets=['PQ', 'ATT']\n",
    "        #keys=['none','mahalanobis','manhattan']\n",
    "        keys=['mahalanobis']\n",
    "    else:\n",
    "#         pathsArr=['../datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "        ##remove the non-normal distributed features\n",
    "        not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "        if data =='study1':\n",
    "#             normality_test_features_path= '../../Tables/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "            normality_test_features_path ='/mnt/vdb1/UX-Ratings/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "        else:\n",
    "#             normality_test_features_path ='Tables/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "            normality_test_features_path ='/mnt/vdb1/UX-Ratings/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "        print(\"reading the normal features from path: \",normality_test_features_path)\n",
    "        mahalanobis = pd.read_csv(normality_test_features_path)\n",
    "        mahalanobis = list(mahalanobis[mahalanobis['Normality']==True]['Features'].values)\n",
    "\n",
    "#         manhattan = pd.read_csv('Tables/Study1/study1_univariate_normality_test_features_manhattan_transformed.csv')\n",
    "#         manhattan = list(manhattan[manhattan['Normality']==True]['Features'].values)\n",
    "        \n",
    "#         none_set = pd.read_csv('tables/Study1/study1_univariate_normality_test_features_none_transformed.csv')\n",
    "#         none_set = list(none_set[none_set['Normality']==True]['Features'].values)\n",
    "        \n",
    "        # print(columns_set[0])\n",
    "        for col in not_columns:\n",
    "        #     print(col)\n",
    "            if(col in mahalanobis):\n",
    "                mahalanobis.remove(col)\n",
    "#             if (col in manhattan): \n",
    "#                 manhattan.remove(col)\n",
    "#             if (col in none_set): \n",
    "#                 none_set.remove(col)\n",
    "        #columns_set=[none_set,mahalanobis,#manhattan]\n",
    "#         columns_set=[mahalanobis]\n",
    "        targets=['PQ', 'ATT']\n",
    "        #keys=[#'none','mahalanobis',#'manhattan']\n",
    "        keys=['mahalanobis_transformedDistributions']\n",
    "    \n",
    "    #store the results\n",
    "    results_r2_val_scores={}\n",
    "    results_r2_test_scores={}\n",
    "    results_r2_train_scores={}\n",
    "    results_rmse_test={}\n",
    "    results_rmse_train={}\n",
    "    results_rmse_val={}\n",
    "    results_adjusted_r2_val_scores={}\n",
    "    results_std_r2_val_scores={}\n",
    "    results={}\n",
    "    results_val_mae={}\n",
    "    results_test_mae={}\n",
    "    results_train_mae={}\n",
    "    predictions={}\n",
    "    results_aic_test={}\n",
    "    results_bic_test={}\n",
    "    results_aic_val={}\n",
    "    results_bic_val={}\n",
    "    results_mape_val={}\n",
    "    results_mape_test={}\n",
    "    for target in targets:\n",
    "        std_val_scores={}\n",
    "        val_scores={}\n",
    "        test_scores ={}\n",
    "        train_scores={}\n",
    "        params_spell={}\n",
    "        rmse_train={}\n",
    "        rmse_test={}\n",
    "        rmse_val={}\n",
    "        mae_val={}\n",
    "        mae_test={}\n",
    "        mae_train={}\n",
    "        adjusted_test={}\n",
    "        bic_val ={}\n",
    "        bic_test ={}\n",
    "        aic_val={}\n",
    "        aic_test={}\n",
    "        mape_val={}\n",
    "        mape_test={}\n",
    "        logging.info('Prediction for {}'.format(target))\n",
    "        print('Prediction for {}'.format(target))\n",
    "        i=0\n",
    "#         print(zip(pathsArr[0],keys))\n",
    "        for path,key in zip([pathsArr[0]],keys):\n",
    "            print(path)\n",
    "            personality=loadDataset(data=data,path=path,target=target)\n",
    "            X=personality.get('data')\n",
    "            zero_var_columns = X.loc[:, X.var() == 0.0].columns\n",
    "            print(\"columns thrown away because they have 0 variance:\",zero_var_columns)\n",
    "            \n",
    "            # removed 0 variance\n",
    "            X = X.loc[:, X.var() != 0.0]\n",
    "           \n",
    "            print(X.isnull().values.any())\n",
    "            \n",
    "            if transformation==True:\n",
    "                X=X[mahalanobis]\n",
    "                print(\"Shape of the data after selected transformed columns:\",X.shape)\n",
    "#                 i=i+1\n",
    "            y=personality.get('target')\n",
    "            \n",
    "            # remove highly correlated data \n",
    "            \n",
    "            # Create correlation matrix\n",
    "            corr_matrix = X.select_dtypes(['float64']).corr().abs()\n",
    "\n",
    "            # Select upper triangle of correlation matrix\n",
    "            upper_traingle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "            # Find index of feature columns with correlation greater than 0.95\n",
    "            to_drop_cols = [column for column in upper_traingle.columns if any(upper_traingle[column] >= 0.80)]\n",
    "            print(to_drop_cols)\n",
    "            # Drop features \n",
    "            X = X.drop(X[to_drop_cols], axis=1)\n",
    "            \n",
    "            print(\"Shape of the data after removing 0 variance highly correlated data:\",X.shape)\n",
    "\n",
    "#             # split the data into train test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "#             X_train =X\n",
    "#             y_train = y\n",
    "            \n",
    "            test = loadDataset(data='study2',path=pathsArr[1],target=target)\n",
    "            X_test = test.get('data')\n",
    "            y_test = test.get('target')\n",
    "            \n",
    "            \n",
    "            # Drop features to make both the datasets schema equal\n",
    "            X_test = X_test.drop(X_test[zero_var_columns], axis=1)\n",
    "            if transformation==True:\n",
    "                X_test=X_test[mahalanobis]\n",
    "            X_test = X_test.drop(X_test[to_drop_cols], axis=1)\n",
    "            \n",
    "            print(\"Shape of the data after removing 0 variance highly correlated data:\",X_test.shape)\n",
    "            print(np.equal(X_train.columns,X_test.columns))\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train=scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            print(np.where(np.isnan(X_train)==True))\n",
    "            \n",
    "            pca= PCA(n_components=n_components)\n",
    "            pca.fit(X_train)\n",
    "            print('number of principal components:',pca.n_components_)\n",
    "            \n",
    "            logging.info('number of principal components: {}'.format(pca.n_components_))\n",
    "            predictors=pca.n_components_\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "            print(\"shape of training data \",X_train.shape)\n",
    "            print(\"shape of test data\",X_test.shape)\n",
    "            logging.info(\"shape of training data {}\".format(X_train.shape))\n",
    "            logging.info(\"shape of test data {}\".format(X_test.shape))\n",
    "                \n",
    "            estimator, best_params_,best_score_,cv_results_,best_index_ = optimalModelSelection(\n",
    "                    model,param_grid,X_train,y_train,method)\n",
    "            \n",
    "            # calculate the RSS on test set\n",
    "            #rss_val = (np.array(y_train)-estimator.predict(X_train)).sum()\n",
    "#             print(\"RSS(Validation): %0.2f\" %(rss_val))\n",
    "            print('Performance(R2):%0.2f'%(best_score_))\n",
    "            # calculate the AIC\n",
    "            y_pred_train  = estimator.fit(X_train,y_train).predict(X_train)\n",
    "            aic_score_val = aic(y_train,y_pred_train,X_train.shape[1])\n",
    "            # calculate Bayesian Information Criterion\n",
    "            bic_score_val = bic(y_train,y_pred_train,X_train.shape[1])\n",
    "            mape_score_val = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100\n",
    "            \n",
    "            # test on unseen data\n",
    "            y_pred = estimator.predict(X_test)\n",
    "            aic_score_test = aic(y_test,y_pred,X_test.shape[1])\n",
    "            bic_score_test = bic(y_test,y_pred,X_test.shape[1])\n",
    "            mape_score_test = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "            \n",
    "            '''TODO: Store the residuals in the table'''\n",
    "            residuals_test = np.array(y_test)- y_pred\n",
    "#             rss_test = np.linalg.norm(np.array(y_test)-estimator.predict(X_test))**2\n",
    "            #print(len(residuals))\n",
    "            \n",
    "            #store it in a seperate table\n",
    "            residuals = np.array(y_train)- y_pred_train\n",
    "#             prediction= {'Original':np.array(y_train),'Predicted':y_pred_train,'Residuals':residuals}\n",
    "            prediction= {'Original':np.array(y_test),'Predicted':y_pred,'Residuals':residuals_test}\n",
    "            predictions[target]=prediction\n",
    "            \n",
    "            score = r2_score(y_test,y_pred)\n",
    "            rmse = np.sqrt(np.abs(mean_squared_error(y_test,y_pred)))\n",
    "            mae = mean_absolute_error(y_test,y_pred)\n",
    "            print('Peforming predictions on unseen data')\n",
    "            print('Performance(R2):%0.2f | RMSE:%0.2f | MAE:%0.2f | AIC:%0.2f | MAPE:%0.2f' %(score,rmse,mae,aic_score_test,mape_score_test))\n",
    "            \n",
    "            #append the result\n",
    "            \n",
    "            # RSquared score\n",
    "            val_scores[key]=best_score_\n",
    "            train_scores[key]=cv_results_['mean_train_r2'][best_index_]\n",
    "            params_spell[key]=best_params_\n",
    "            test_scores[key]=score\n",
    "            \n",
    "            # RMSE \n",
    "            rmse_train[key]=np.sqrt(np.abs(cv_results_['mean_train_mse'][best_index_]))\n",
    "            std_val_scores[key]= cv_results_['std_test_r2'][best_index_]\n",
    "            rmse_val[key]= np.sqrt(np.abs(cv_results_['mean_test_mse'][best_index_]))\n",
    "            rmse_test[key]=rmse\n",
    "            \n",
    "            # Adjusted RSquared\n",
    "            adjusted_test[key]=1 - (1-best_score_)*(len(y_train)-1)/(len(y_train)-predictors-1)\n",
    "            \n",
    "            # MAE \n",
    "            mae_train[key]= -cv_results_['mean_train_mae'][best_index_]\n",
    "            mae_val[key]= -cv_results_['mean_test_mae'][best_index_]\n",
    "            mae_test[key]=mae\n",
    "            \n",
    "            #AIC / BIC \n",
    "            aic_val[key]=aic_score_val\n",
    "            aic_test[key]= aic_score_test\n",
    "            bic_val[key]=bic_score_val\n",
    "            bic_test[key]=bic_score_test\n",
    "            \n",
    "            #MAPE\n",
    "            mape_val[key]=mape_score_val\n",
    "            mape_test[key]=mape_score_test\n",
    "            \n",
    "            print('*'*100)\n",
    "            logging.info('*'*100)\n",
    "                \n",
    "        results_r2_val_scores[target]=val_scores\n",
    "        results_r2_train_scores[target]=train_scores\n",
    "        results_rmse_val[target]=rmse_val\n",
    "        results_rmse_train[target]=rmse_train\n",
    "        results_adjusted_r2_val_scores[target]=adjusted_test\n",
    "        results_rmse_test[target]=rmse_test\n",
    "        results_r2_test_scores[target]=test_scores\n",
    "        results_std_r2_val_scores[target]=std_val_scores\n",
    "        results_val_mae[target]=mae_val\n",
    "        results_train_mae[target]=mae_train\n",
    "        results_test_mae[target]=mae_test\n",
    "        results_aic_test[target]=aic_test\n",
    "        results_aic_val[target]=aic_val\n",
    "        results_bic_test[target]=bic_test\n",
    "        results_bic_val[target]=bic_val\n",
    "        results_mape_val[target]=mape_val\n",
    "        results_mape_test[target]=mape_test\n",
    "    \n",
    "    results['r2_train']=results_r2_train_scores\n",
    "    results['r2_validation']=results_r2_val_scores\n",
    "    results['rmse_train']=results_rmse_test\n",
    "    results['rmse_validation']=results_rmse_val\n",
    "    results['rmse_test']=results_rmse_test\n",
    "    results['r2_test']=results_r2_test_scores\n",
    "    results['std_validation']= results_r2_test_scores\n",
    "    results['std_validation']= results_std_r2_val_scores\n",
    "    results['adjusted_r2_val']=results_adjusted_r2_val_scores\n",
    "    results['mae_train']=results_train_mae\n",
    "    results['mae_validation']=results_val_mae\n",
    "    results['mae_test']=results_test_mae\n",
    "    results['mae_test']=results_test_mae\n",
    "    results['aic_test']=results_aic_test\n",
    "    results['aic_validation']=results_aic_val\n",
    "    results['bic_test']=results_bic_test\n",
    "    results['bic_validation']=results_bic_val\n",
    "    results['mape_validation']=results_mape_val\n",
    "    results['mape_test']=results_mape_test\n",
    "        \n",
    "    print('*'*100)\n",
    "    logging.info('*'*100)\n",
    "    return results, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAllModels(pathsArr, filename,data='study1',transformation=False,n_components=0.95):\n",
    "    # #create models\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    #linear regression\n",
    "    logging.info('********Applying Linear Regression****************')\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "#     fit_intercept_space=[True,False]\n",
    "#     normalize_space=[True,False]\n",
    "    fit_intercept_space=[True]\n",
    "    param_grid={'fit_intercept':fit_intercept_space,\n",
    "#                 'normalize':normalize_space\n",
    "               }\n",
    "    regr= LinearRegression()\n",
    "    results_regr,predictions_regr= perform_evaluation(pathsArr,regr,param_grid,data=data,transformation=transformation,n_components=n_components)\n",
    "#     print(results_regr)\n",
    "\n",
    "    ## lasso regression\n",
    "    logging.info('********Applying Lasso Regression****************')\n",
    "    from sklearn.linear_model import Lasso\n",
    "    alpha_space = np.logspace(0, 1, 100)\n",
    "#     alpha_space = [0.001,0.01,0.1,1.0,2,3]\n",
    "    param_grid={'alpha':alpha_space}\n",
    "    lasso = Lasso(random_state=32)\n",
    "    results_lasso,predictions_lasso = perform_evaluation(pathsArr,lasso,param_grid,data=data,\n",
    "                                                        transformation=transformation,n_components=n_components)\n",
    "    \n",
    "\n",
    "\n",
    "    ## elastic net \n",
    "    logging.info('********Applying Elastic Net Regression****************')\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    alpha_space = np.logspace(0, 2 , 50)\n",
    "    param_grid={'alpha':alpha_space}\n",
    "    enet = ElasticNet(random_state=32)\n",
    "    results_enet,predictions_enet = perform_evaluation(pathsArr,enet,param_grid,data=data,transformation=transformation,n_components=n_components)\n",
    "\n",
    "    # ##create models\n",
    "    np.random.seed(19)\n",
    "    # support vector machines\n",
    "    logging.info('********Applying Support vector machine****************')\n",
    "    from sklearn.svm import SVR\n",
    "    C_space=np.logspace(-1,1,10)\n",
    "#     C_space = np.logspace(-2, 10, 5)\n",
    "    epsilon_space= np.logspace(-1,0,10)\n",
    "#     epsilon_space=np.logspace(-1,2,5)\n",
    "    gamma_space = np.logspace(-3, -2, 10)\n",
    "#     gamma_space='scale'\n",
    "    param_grid={'C':C_space,'epsilon':epsilon_space,'gamma':gamma_space}\n",
    "    svr = SVR(kernel = 'rbf')\n",
    "    results_svm,predictions_svm = perform_evaluation(pathsArr,svr,param_grid,method='random',data=data,transformation=transformation,n_components=n_components)\n",
    "\n",
    "\n",
    "#     # random forest\n",
    "#     logging.info('********Applying Random Forest****************')\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "#     n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# #     n_estimators=[500,1000]\n",
    "#     max_depth = [int(x) for x in np.linspace(10, 20, num = 11)]\n",
    "#     min_samples_split = [2, 5, 10,15]\n",
    "#     min_samples_leaf = [5,10,50,100,200]\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "\n",
    "    max_depth = [int(x) for x in np.linspace(1, 5, num = 5)]\n",
    "\n",
    "    min_samples_split = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(10, 60, num = 20)]\n",
    "    bootstrap = [True, False]\n",
    "#     max_features=['sqrt']\n",
    "    max_features=['auto','sqrt']\n",
    "    param_grid={'n_estimators': n_estimators,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "#                     'bootstrap': bootstrap,\n",
    "                    'max_features':max_features\n",
    "                   }   \n",
    "    rf = RandomForestRegressor(random_state=32)\n",
    "    results_rf,predictions_rf= perform_evaluation(pathsArr,rf,param_grid,method='random',data=data,transformation=transformation,n_components=n_components)\n",
    "\n",
    "    #Linear regression using stochastic gradient descent\n",
    "    logging.info('********Applying Linear regression with stochastic gradient descent****************')\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    param_grid={#'max_iter':[100,500,1000],\n",
    "                'max_iter':[50,100],\n",
    "                'penalty':[None],\n",
    "                'eta0':[0.01,0.1,0.5]\n",
    "                   }\n",
    "    sgd_reg = SGDRegressor(random_state=32)\n",
    "    results_sgd,predictions_sgd = perform_evaluation(pathsArr,sgd_reg,param_grid,data=data,transformation=transformation,n_components=n_components)\n",
    "#     results_sgd\n",
    "\n",
    "#     # MARS\n",
    "    np.random.seed(20)\n",
    "    logging.info('********Applying MARS****************')\n",
    "    from pyearth import Earth\n",
    "    max_degree_space=[1]\n",
    "    #penalty_space=[3.0,6.0]\n",
    "   # minspan_alpha = np.linspace(0, 0.5, num = 10)\n",
    "    penalty_space=np.logspace(-1,1,20)\n",
    "    minspan_alpha=np.logspace(-3,1,20)\n",
    "    max_terms=[10,20,25]\n",
    "#     max_terms=np.linspace(25,30,num=5)\n",
    "    endspan_alpha = [0.05]\n",
    "    # # endspan_alpha= np.linspace(0, 1.0, num = 10)\n",
    "    # # endspan=[5]\n",
    "    param_grid={'max_degree':max_degree_space,\n",
    "        'penalty':penalty_space,\n",
    "             #  'minspan_alpha':minspan_alpha,\n",
    "        #'endspan_alpha':endspan_alpha,\n",
    "                'use_fast':[True],\n",
    "        'max_terms':max_terms\n",
    "               }\n",
    "    mars= Earth()\n",
    "    results_mars,predictions_mars= perform_evaluation(pathsArr,mars,param_grid,method='grid',data=data,transformation=transformation,n_components=n_components)\n",
    "    results_mars\n",
    "    \n",
    "    def createTable(results,name):\n",
    "        '''Creates the final table'''\n",
    "        df= pd.concat([pd.DataFrame(results.get('r2_test')).T,\n",
    "        pd.DataFrame(results.get('r2_train')).T,\n",
    "                  pd.DataFrame(results.get('r2_validation')).T,\n",
    "        pd.DataFrame(results.get('rmse_test')).T,\n",
    "                  pd.DataFrame(results.get('rmse_train')).T,\n",
    "        pd.DataFrame(results.get('rmse_validation')).T,\n",
    "                  pd.DataFrame(results.get('std_validation')).T,\n",
    "                     pd.DataFrame(results.get('adjusted_r2_val')).T,\n",
    "                       pd.DataFrame(results.get('mae_train')).T,\n",
    "                      pd.DataFrame(results.get('mae_validation')).T,\n",
    "                      pd.DataFrame(results.get('mae_test')).T,\n",
    "                      pd.DataFrame(results.get('aic_validation')).T,\n",
    "                      pd.DataFrame(results.get('aic_test')).T,\n",
    "                      pd.DataFrame(results.get('bic_validation')).T,\n",
    "                      pd.DataFrame(results.get('bic_test')).T,\n",
    "                      pd.DataFrame(results.get('mape_validation')).T,\n",
    "                      pd.DataFrame(results.get('mape_test')).T],axis=1)\n",
    "        \n",
    "        df.columns=['R2(Test)','R2(Train)','R2(Validation)',\n",
    "                    'RMSE(Test)','RMSE(Train)','RMSE(Validation)',\n",
    "                    'StandardError(Validation)',\n",
    "                    'Adjusted R2(Validation)',\n",
    "                    'MAE(Train)','MAE(Validation)','MAE(Test)',\n",
    "                    'AIC(Validation)','AIC(Test)','BIC(Validation)','BIC(Test)',\n",
    "                   'MAPE(Validation)','MAPE(Test)']\n",
    "        df['Target']=df.index\n",
    "        df['Algorithm']=name\n",
    "        df= df.reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    df_sgd=createTable(results_sgd,name='Linear Regression SGD')\n",
    "    df_lasso=createTable(results_lasso,name='Lasso Regression')\n",
    "    df_enet=createTable(results_enet,name='Elastic Net')\n",
    "    df_svm=createTable(results_svm,name='SVM')\n",
    "    df_rf=createTable(results_rf,name='Random Forest')\n",
    "    df_mars=createTable(results_mars,name='MARS')\n",
    "    df_lr=createTable(results_regr,name='Linear Regression')\n",
    "    \n",
    "    pd.concat([\n",
    "        df_rf,df_svm,df_sgd,\n",
    "        df_lr,\n",
    "        df_lasso,\n",
    "        df_enet,df_mars\n",
    "    ]).to_csv(filename,index=False)\n",
    "    \n",
    "#     del df_sgd,df_lasso,df_enet,df_svm,df_rf,df_mars\n",
    "    \n",
    "    def createPredictionsTable(predictions):\n",
    "        pq= pd.DataFrame(predictions.get('PQ'))\n",
    "        pq.rename(index=str, columns={\"Original\": \"Original_PQ\", \"Prediction\": \"Prediction_PQ\",'Residuals':'Residuals_PQ'}, inplace=True)\n",
    "        att=pd.DataFrame(predictions.get('ATT'))\n",
    "        att.rename(index=str, columns={\"Original\": \"Original_ATT\", \"Prediction\": \"Prediction_ATT\",'Residuals':'Residuals_ATT'},inplace=True)\n",
    "        df = pd.concat([pq,att],axis=1)\n",
    "        return df\n",
    "    \n",
    "    df_sgd=createPredictionsTable(predictions_sgd)\n",
    "    df_lasso=createPredictionsTable(predictions_lasso)\n",
    "    df_enet=createPredictionsTable(predictions_enet)\n",
    "    df_svm=createPredictionsTable(predictions_svm)\n",
    "    df_rf=createPredictionsTable(predictions_rf)\n",
    "    df_mars=createPredictionsTable(predictions_mars)\n",
    "    df_lr=createPredictionsTable(predictions_regr)\n",
    "    \n",
    "#     print(df_lasso)\n",
    "    if transformation==False:\n",
    "        filename=str(data)+'_PCA_alltargets_mahalanobis_'+str(n_components)+'_predictions_unseen.xlsx'\n",
    "    else:\n",
    "        filename=str(data)+'_PCA_alltargets_mahalanobis_transformed_'+str(n_components)+'_predictions_unseen.xlsx'\n",
    "        \n",
    "    with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
    "        df_sgd.to_excel(writer, sheet_name='Linear Regression SGD')\n",
    "        df_lasso.to_excel(writer, sheet_name='Lasso Regression')\n",
    "        df_enet.to_excel(writer, sheet_name='Elastic Net')\n",
    "        df_svm.to_excel(writer, sheet_name='SVM')\n",
    "        df_rf.to_excel(writer, sheet_name='Random Forest')\n",
    "        df_mars.to_excel(writer, sheet_name='MARS')\n",
    "        df_lr.to_excel(writer, sheet_name='LR')\n",
    "    \n",
    "    print('File saved successfully')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for checking the function\n",
    "# # uncomment it when you want\n",
    "\n",
    "# pathsArr=['../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "# transformation=False\n",
    "# n_components=0.95\n",
    "# data='study1'\n",
    "# from sklearn.linear_model import Lasso\n",
    "# alpha_space = np.logspace(0, 1, 100)\n",
    "# #     alpha_space = [0.001,0.01,0.1,1.0,2,3]\n",
    "# param_grid={'alpha':alpha_space}\n",
    "# lasso = Lasso(random_state=32)\n",
    "# results_lasso,predictions_lasso = perform_evaluation(pathsArr,lasso,param_grid,data=data,\n",
    "#                                                         transformation=transformation,n_components=n_components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study1 original and test on Study2 Original\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on study1 data and test on study2 on original distribution with 95% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv',\n",
    "         '/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv']\n",
    "#     path = ['../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv',\n",
    "#          '../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_0.95PC.csv'\n",
    "    runAllModels(path,filename,data='study1',transformation=False,n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on study1 data and test on study2 on original distribution with 80% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv',\n",
    "         '/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_0.80PC.csv'\n",
    "    runAllModels(path,filename,data='study1',transformation=False,n_components=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on study1 data and test on study2 on original distribution with 3 PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv',\n",
    "         '/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_3PC.csv'\n",
    "    runAllModels(path,filename,data='study1',transformation=False,n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study1 transformation and test on Study2 transformation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on transformed distributions of study1 data and test on study2 with 95% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "         '/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "#     path=['../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "#          '../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_transformed_0.95PC.csv'\n",
    "    runAllModels(path,filename,data='study1',transformation=True,n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on transformed distributions of study1 data and test on study2 with 80% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "         '/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_transformed_0.80PC.csv'\n",
    "    runAllModels(path,filename,data='study1',transformation=True,n_components=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on transformed distributions of study1 data and test on study2 with 3PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "         '/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_transformed_3PC.csv'\n",
    "    runAllModels(path,filename,data='study1',transformation=True,n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
