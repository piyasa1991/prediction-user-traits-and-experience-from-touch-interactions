{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Script to run the ML algorithms on the reduced dimensions generated by PCA for STUDY2 and test on STUDY1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "LOG_FILENAME = 'UX_Ratings_PCA.log'\n",
    "logging.basicConfig(filename=LOG_FILENAME,level=logging.INFO)\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import KFold,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from RegscorePy.aic import aic # for calculating Akaikeâ€™s Information Criterion\n",
    "from RegscorePy.bic import bic # for calculating Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataFromCsv(file):\n",
    "    import pandas as pd\n",
    "    print (\"Reading the file from: \",file)\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "def loadDataset(data='study1',path='../datasets/files_generated/UX/study1_features_data.csv',target='PQ',app='Spell'):    \n",
    "#     if data== 'study1':\n",
    "    df = readDataFromCsv(path)\n",
    "#     if data=='study2':\n",
    "#         df = readDataFromCsv(path)\n",
    "    df=df[df['App']==app]   \n",
    "    print('The shape of the data  currently: ',df.shape)\n",
    "    \n",
    "    ## This should not have been there\n",
    "    if(df.isnull().values.any()==True and data=='study1'):\n",
    "        df = df.dropna()\n",
    "        print('The shape of the data after dropping null values: ',df.shape)\n",
    "    if data == 'startData':\n",
    "#         df_join= pd.merge(df_stat_summ_withoutna, df_ux, on=['user_id','App','Cond','sessionNr'])\n",
    "        X,y= df.drop(['PQ', 'ATT', 'HQI', 'HQS', 'HQ'],axis=1),df[target]\n",
    "    elif data=='study1':\n",
    "#         df_join= pd.merge(df_stat_summ_withoutna, df_ux, on=['user_id','App','Cond','sessionNr'])\n",
    "        X,y= df.drop(['user_id','App','Cond','sessionNr','SEA', 'PQ', 'ATT', 'HQI', 'HQS', 'HQ'],axis=1),df[target]\n",
    "    elif data=='study2':\n",
    "#         df_join= pd.merge(df_stat_summ_withoutna, df_ux, how='inner',left_on=['user_id','Cond','sessionNr'],\n",
    "#                            right_on=['UserId','IconSize','Session'])\n",
    "        X,y=df.drop(['sessionNr','App','user_id','Size','UserId', 'Session', \n",
    "                     'PQ', 'ATT', 'HQI', 'HQS', 'HQ', 'IconSize'],axis=1),df[target]\n",
    "        print(X.shape)\n",
    "#     print('shape after join: ',df_join.shape)\n",
    "    df_result={'data':X,'target':y}\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=['../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv']\n",
    "# target='PQ'\n",
    "# data='study2'\n",
    "# dd = loadDataset(path=path[0],target=target,data=data)\n",
    "# X = dd.get('data')\n",
    "# y = dd.get('target')\n",
    "\n",
    "\n",
    "# print(\"shape:\",X.shape)\n",
    "\n",
    "# # remove 0 variance\n",
    "# col_index = np.where(X.var()!=0)\n",
    "# columns = X.loc[:, X.var()== 0.0].columns.values\n",
    "# X = X.loc[:, X.var() != 0.0]\n",
    "\n",
    "# not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "# if data =='study1':\n",
    "#     normality_test_features_path= 'Tables/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# else:\n",
    "#     normality_test_features_path ='Tables/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# print(\"reading the normal features from path: \",normality_test_features_path)\n",
    "# mahalanobis = pd.read_csv(normality_test_features_path)\n",
    "# mahalanobis = list(mahalanobis[mahalanobis['Normality']==True]['Features'].values)\n",
    "# for col in not_columns:\n",
    "#     if(col in mahalanobis):\n",
    "#         mahalanobis.remove(col)\n",
    "\n",
    "# # X=X[mahalanobis]\n",
    "\n",
    "# # Create correlation matrix\n",
    "# corr_matrix = X.corr().abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper_traingle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop_cols = [column for column in upper_traingle.columns if any(upper_traingle[column] >= 0.80)]\n",
    "\n",
    "# # Drop features \n",
    "# X = X.drop(X[to_drop_cols], axis=1)\n",
    "# print(\"current shape:\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normality_test_features_path= 'Tables/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# mahalanobis_study1 = pd.read_csv(normality_test_features_path)\n",
    "# mahalanobis_study1 = list(mahalanobis_study1[mahalanobis_study1['Normality']==True]['Features'].values)\n",
    "# not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "# for col in not_columns:\n",
    "#     if(col in mahalanobis_study1):\n",
    "#         mahalanobis_study1.remove(col)\n",
    "\n",
    "# normality_test_features_path= 'Tables/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "# mahalanobis_study2 = pd.read_csv(normality_test_features_path)\n",
    "# mahalanobis_study2 = list(mahalanobis_study2[mahalanobis_study2['Normality']==True]['Features'].values)\n",
    "# not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "# for col in not_columns:\n",
    "#     if(col in mahalanobis_study2):\n",
    "#         mahalanobis_study2.remove(col)\n",
    "        \n",
    "# set1=set(mahalanobis_study1)\n",
    "# set2=set(mahalanobis_study2)\n",
    "\n",
    "# missing = list(sorted(set1 - set2))\n",
    "# added = list(sorted(set2 - set1))\n",
    "\n",
    "# print('missing:', missing)\n",
    "# print('added:', added)\n",
    "# print(len(mahalanobis_study1))\n",
    "# print(len(mahalanobis_study2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalModelSelection(model,param_grid,X,y,method='grid'):\n",
    "    '''Tune the hyperparameters to find the best score personality data'''\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "    from sklearn.pipeline import make_pipeline,Pipeline\n",
    "    from sklearn.model_selection import KFold,GridSearchCV,RandomizedSearchCV\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "#     K = 10\n",
    "#     kf = KFold(n_splits=K, shuffle=True,random_state=32)\n",
    "    \n",
    "    scoring={'r2':'r2','mse':'neg_mean_squared_error','mae':'neg_mean_absolute_error'}\n",
    "#     pca = PCA(random_state=32,svd_solver='full')\n",
    "#     pipe = Pipeline([('scl', StandardScaler()),\n",
    "#                      ('pca',pca),\n",
    "#                     ('clf', model)])\n",
    "    if(method=='grid'):\n",
    "        search = GridSearchCV(model, param_grid, cv=10,n_jobs=-1,scoring=scoring,return_train_score=True,refit='r2')\n",
    "        search.fit(X,y)\n",
    "    if(method=='random'):\n",
    "        search=RandomizedSearchCV(estimator = model, param_distributions = param_grid, \n",
    "                               n_iter = 100, cv = 10, verbose=1, \n",
    "                               random_state=32, n_jobs = -1,scoring=scoring,return_train_score=True,refit='r2')\n",
    "        search.fit(X,y)\n",
    "    \n",
    "#     logging.info('Reduced dimension for 98% variance: {}'.format(search.best_estimator_.named_steps['pca'].components_.shape))\n",
    "#     logging.info('Reduced dimension: {}'.format(search.best_estimator_.named_steps['pca'].n_components_))\n",
    "    \n",
    "    print('Best params: {}'.format(search.best_params_))\n",
    "    logging.info('Best params: {}'.format(search.best_params_))\n",
    "#     print('Best score after fitting the estimator with best params:{}'.format(search.best_score_))\n",
    "#     logging.info('Best score after fitting the estimator with best params:{}'.format(search.best_score_))\n",
    "    print('RMSE: %0.2f'%(np.sqrt(-search.cv_results_['mean_test_mse'][search.best_index_])))\n",
    "    print(\"R2(Validation): %0.2f (+/- %0.2f)\" % (search.best_score_,search.cv_results_['std_test_r2'][search.best_index_]))\n",
    "    print(\"R2(Train): %0.2f (+/- %0.2f)\" % (search.cv_results_['mean_train_r2'][search.best_index_],\n",
    "                                                 search.cv_results_['std_train_r2'][search.best_index_]))\n",
    "    print(\"MAE(Validation): %0.2f (+/- %0.2f)\" % (-search.cv_results_['mean_test_mae'][search.best_index_],\n",
    "                                                  search.cv_results_['std_test_mae'][search.best_index_]))\n",
    "    print(\"MAE(Train): %0.2f (+/- %0.2f)\" % (-search.cv_results_['mean_train_mae'][search.best_index_],\n",
    "                                                 search.cv_results_['std_train_mae'][search.best_index_]))\n",
    "    \n",
    "    logging.info('RMSE: %0.2f'%(np.sqrt(-search.cv_results_['mean_test_mse'][search.best_index_])))\n",
    "    logging.info(\"R2: %0.2f (+/- %0.2f)\" % (search.best_score_,search.cv_results_['std_test_r2'][search.best_index_]))\n",
    "    return search.best_estimator_,search.best_params_, search.best_score_,search.cv_results_,search.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_evaluation(pathsArr,model,param_grid,method='grid',data='study1',transformation=False,n_components=0.95):\n",
    "    \n",
    "    if transformation==False:\n",
    "#         pathsArr=['../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "        targets=['PQ', 'ATT']\n",
    "        #keys=['none','mahalanobis','manhattan']\n",
    "        keys=['mahalanobis']\n",
    "    else:\n",
    "#         pathsArr=['../datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "        ##remove the non-normal distributed features\n",
    "        not_columns=['SEA','PQ','ATT', 'HQI', 'HQ','HQS']\n",
    "        if data =='study1':\n",
    "#             normality_test_features_path= '../../Tables/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "            normality_test_features_path ='/mnt/vdb1/UX-Ratings/NormalityCheck/study1_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "        else:\n",
    "#             normality_test_features_path ='../../Tables/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "            normality_test_features_path ='/mnt/vdb1/UX-Ratings/NormalityCheck/study2_univariate_normality_test_features_mahalanobis_transformed.csv'\n",
    "        print(\"reading the normal features from path: \",normality_test_features_path)\n",
    "        mahalanobis = pd.read_csv(normality_test_features_path)\n",
    "        mahalanobis = list(mahalanobis[mahalanobis['Normality']==True]['Features'].values)\n",
    "\n",
    "#         manhattan = pd.read_csv('Tables/Study1/study1_univariate_normality_test_features_manhattan_transformed.csv')\n",
    "#         manhattan = list(manhattan[manhattan['Normality']==True]['Features'].values)\n",
    "        \n",
    "#         none_set = pd.read_csv('tables/Study1/study1_univariate_normality_test_features_none_transformed.csv')\n",
    "#         none_set = list(none_set[none_set['Normality']==True]['Features'].values)\n",
    "        \n",
    "        # print(columns_set[0])\n",
    "        for col in not_columns:\n",
    "        #     print(col)\n",
    "            if(col in mahalanobis):\n",
    "                mahalanobis.remove(col)\n",
    "#             if (col in manhattan): \n",
    "#                 manhattan.remove(col)\n",
    "#             if (col in none_set): \n",
    "#                 none_set.remove(col)\n",
    "        #columns_set=[none_set,mahalanobis,#manhattan]\n",
    "#         columns_set=[mahalanobis]\n",
    "        targets=['PQ', 'ATT']\n",
    "        #keys=[#'none','mahalanobis',#'manhattan']\n",
    "        keys=['mahalanobis_transformedDistributions']\n",
    "    \n",
    "    #store the results\n",
    "    results_r2_val_scores={}\n",
    "    results_r2_test_scores={}\n",
    "    results_r2_train_scores={}\n",
    "    results_rmse_test={}\n",
    "    results_rmse_train={}\n",
    "    results_rmse_val={}\n",
    "    results_adjusted_r2_val_scores={}\n",
    "    results_std_r2_val_scores={}\n",
    "    results={}\n",
    "    results_val_mae={}\n",
    "    results_test_mae={}\n",
    "    results_train_mae={}\n",
    "    predictions={}\n",
    "    results_aic_test={}\n",
    "    results_bic_test={}\n",
    "    results_aic_val={}\n",
    "    results_bic_val={}\n",
    "    results_mape_val={}\n",
    "    results_mape_test={}\n",
    "    for target in targets:\n",
    "        std_val_scores={}\n",
    "        val_scores={}\n",
    "        test_scores ={}\n",
    "        train_scores={}\n",
    "        params_spell={}\n",
    "        rmse_train={}\n",
    "        rmse_test={}\n",
    "        rmse_val={}\n",
    "        mae_val={}\n",
    "        mae_test={}\n",
    "        mae_train={}\n",
    "        adjusted_test={}\n",
    "        bic_val ={}\n",
    "        bic_test ={}\n",
    "        aic_val={}\n",
    "        aic_test={}\n",
    "        mape_val={}\n",
    "        mape_test={}\n",
    "        logging.info('Prediction for {}'.format(target))\n",
    "        print('Prediction for {}'.format(target))\n",
    "        i=0\n",
    "#         print(zip(pathsArr[0],keys))\n",
    "        for path,key in zip([pathsArr[0]],keys):\n",
    "            print(path)\n",
    "            personality=loadDataset(data=data,path=path,target=target)\n",
    "            X=personality.get('data')\n",
    "            zero_var_columns = X.loc[:, X.var() == 0.0].columns\n",
    "            print(\"columns thrown away because they have 0 variance:\",zero_var_columns)\n",
    "            \n",
    "            # removed 0 variance\n",
    "            X = X.loc[:, X.var() != 0.0]\n",
    "           \n",
    "            print(X.isnull().values.any())\n",
    "            \n",
    "            if transformation==True:\n",
    "                X=X[mahalanobis]\n",
    "                print(\"Shape of the data after selected transformed columns:\",X.shape)\n",
    "#                 i=i+1\n",
    "            y=personality.get('target')\n",
    "            \n",
    "            # remove highly correlated data \n",
    "            \n",
    "            # Create correlation matrix\n",
    "            corr_matrix = X.select_dtypes(['float64']).corr().abs()\n",
    "\n",
    "            # Select upper triangle of correlation matrix\n",
    "            upper_traingle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "            # Find index of feature columns with correlation greater than 0.95\n",
    "            to_drop_cols = [column for column in upper_traingle.columns if any(upper_traingle[column] >= 0.80)]\n",
    "            print(to_drop_cols)\n",
    "            # Drop features \n",
    "            X = X.drop(X[to_drop_cols], axis=1)\n",
    "            \n",
    "            print(\"Shape of the data after removing 0 variance highly correlated data:\",X.shape)\n",
    "\n",
    "#             # split the data into train test set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "#             X_train =X\n",
    "#             y_train = y\n",
    "            \n",
    "            test = loadDataset(data='study1',path=pathsArr[1],target=target)\n",
    "            X_test = test.get('data')\n",
    "            y_test = test.get('target')\n",
    "            \n",
    "            \n",
    "            # Drop features to make both the datasets schema equal\n",
    "            X_test = X_test.drop(X_test[zero_var_columns], axis=1)\n",
    "            if transformation==True:\n",
    "                X_test=X_test[mahalanobis]\n",
    "            X_test = X_test.drop(X_test[to_drop_cols], axis=1)\n",
    "            \n",
    "            print(\"Shape of the data after removing 0 variance highly correlated data:\",X_test.shape)\n",
    "            print(np.equal(X_train.columns,X_test.columns))\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train)\n",
    "            X_train=scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            print(np.where(np.isnan(X_train)==True))\n",
    "            \n",
    "            pca= PCA(n_components=n_components)\n",
    "            pca.fit(X_train)\n",
    "            print('number of principal components:',pca.n_components_)\n",
    "            \n",
    "            logging.info('number of principal components: {}'.format(pca.n_components_))\n",
    "            predictors=pca.n_components_\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "            print(\"shape of training data \",X_train.shape)\n",
    "            print(\"shape of test data\",X_test.shape)\n",
    "            logging.info(\"shape of training data {}\".format(X_train.shape))\n",
    "            logging.info(\"shape of test data {}\".format(X_test.shape))\n",
    "                \n",
    "            estimator, best_params_,best_score_,cv_results_,best_index_ = optimalModelSelection(\n",
    "                    model,param_grid,X_train,y_train,method)\n",
    "            \n",
    "            # calculate the RSS on test set\n",
    "            #rss_val = (np.array(y_train)-estimator.predict(X_train)).sum()\n",
    "#             print(\"RSS(Validation): %0.2f\" %(rss_val))\n",
    "            print('Performance(R2):%0.2f'%(best_score_))\n",
    "            # calculate the AIC\n",
    "            y_pred_train  = estimator.fit(X_train,y_train).predict(X_train)\n",
    "            aic_score_val = aic(y_train,y_pred_train,X_train.shape[1])\n",
    "            # calculate Bayesian Information Criterion\n",
    "            bic_score_val = bic(y_train,y_pred_train,X_train.shape[1])\n",
    "            mape_score_val = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100\n",
    "            \n",
    "            # test on unseen data\n",
    "            y_pred = estimator.predict(X_test)\n",
    "            aic_score_test = aic(y_test,y_pred,X_test.shape[1])\n",
    "            bic_score_test = bic(y_test,y_pred,X_test.shape[1])\n",
    "            mape_score_test = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "            \n",
    "            '''TODO: Store the residuals in the table'''\n",
    "            residuals_test = np.array(y_test)- y_pred\n",
    "#             rss_test = np.linalg.norm(np.array(y_test)-estimator.predict(X_test))**2\n",
    "            #print(len(residuals))\n",
    "            \n",
    "            #store it in a seperate table\n",
    "            residuals = np.array(y_train)- y_pred_train\n",
    "#             prediction= {'Original':np.array(y_train),'Predicted':y_pred_train,'Residuals':residuals}\n",
    "            prediction= {'Original':np.array(y_test),'Predicted':y_pred,'Residuals':residuals_test}\n",
    "            predictions[target]=prediction\n",
    "            \n",
    "            score = r2_score(y_test,y_pred)\n",
    "            rmse = np.sqrt(np.abs(mean_squared_error(y_test,y_pred)))\n",
    "            mae = mean_absolute_error(y_test,y_pred)\n",
    "            print('Peforming predictions on unseen data')\n",
    "            print('Performance(R2):%0.2f | RMSE:%0.2f | MAE:%0.2f | AIC:%0.2f | MAPE:%0.2f' %(score,rmse,mae,aic_score_test,mape_score_test))\n",
    "            \n",
    "            #append the result\n",
    "            \n",
    "            # RSquared score\n",
    "            val_scores[key]=best_score_\n",
    "            train_scores[key]=cv_results_['mean_train_r2'][best_index_]\n",
    "            params_spell[key]=best_params_\n",
    "            test_scores[key]=score\n",
    "            \n",
    "            # RMSE \n",
    "            rmse_train[key]=np.sqrt(np.abs(cv_results_['mean_train_mse'][best_index_]))\n",
    "            std_val_scores[key]= cv_results_['std_test_r2'][best_index_]\n",
    "            rmse_val[key]= np.sqrt(np.abs(cv_results_['mean_test_mse'][best_index_]))\n",
    "            rmse_test[key]=rmse\n",
    "            \n",
    "            # Adjusted RSquared\n",
    "            adjusted_test[key]=1 - (1-best_score_)*(len(y_train)-1)/(len(y_train)-predictors-1)\n",
    "            \n",
    "            # MAE \n",
    "            mae_train[key]= -cv_results_['mean_train_mae'][best_index_]\n",
    "            mae_val[key]= -cv_results_['mean_test_mae'][best_index_]\n",
    "            mae_test[key]=mae\n",
    "            \n",
    "            #AIC / BIC \n",
    "            aic_val[key]=aic_score_val\n",
    "            aic_test[key]= aic_score_test\n",
    "            bic_val[key]=bic_score_val\n",
    "            bic_test[key]=bic_score_test\n",
    "            \n",
    "            #MAPE\n",
    "            mape_val[key]=mape_score_val\n",
    "            mape_test[key]=mape_score_test\n",
    "            \n",
    "            print('*'*100)\n",
    "            logging.info('*'*100)\n",
    "                \n",
    "        results_r2_val_scores[target]=val_scores\n",
    "        results_r2_train_scores[target]=train_scores\n",
    "        results_rmse_val[target]=rmse_val\n",
    "        results_rmse_train[target]=rmse_train\n",
    "        results_adjusted_r2_val_scores[target]=adjusted_test\n",
    "        results_rmse_test[target]=rmse_test\n",
    "        results_r2_test_scores[target]=test_scores\n",
    "        results_std_r2_val_scores[target]=std_val_scores\n",
    "        results_val_mae[target]=mae_val\n",
    "        results_train_mae[target]=mae_train\n",
    "        results_test_mae[target]=mae_test\n",
    "        results_aic_test[target]=aic_test\n",
    "        results_aic_val[target]=aic_val\n",
    "        results_bic_test[target]=bic_test\n",
    "        results_bic_val[target]=bic_val\n",
    "        results_mape_val[target]=mape_val\n",
    "        results_mape_test[target]=mape_test\n",
    "    \n",
    "    results['r2_train']=results_r2_train_scores\n",
    "    results['r2_validation']=results_r2_val_scores\n",
    "    results['rmse_train']=results_rmse_test\n",
    "    results['rmse_validation']=results_rmse_val\n",
    "    results['rmse_test']=results_rmse_test\n",
    "    results['r2_test']=results_r2_test_scores\n",
    "    results['std_validation']= results_r2_test_scores\n",
    "    results['std_validation']= results_std_r2_val_scores\n",
    "    results['adjusted_r2_val']=results_adjusted_r2_val_scores\n",
    "    results['mae_train']=results_train_mae\n",
    "    results['mae_validation']=results_val_mae\n",
    "    results['mae_test']=results_test_mae\n",
    "    results['mae_test']=results_test_mae\n",
    "    results['aic_test']=results_aic_test\n",
    "    results['aic_validation']=results_aic_val\n",
    "    results['bic_test']=results_bic_test\n",
    "    results['bic_validation']=results_bic_val\n",
    "    results['mape_validation']=results_mape_val\n",
    "    results['mape_test']=results_mape_test\n",
    "        \n",
    "    print('*'*100)\n",
    "    logging.info('*'*100)\n",
    "    return results, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAllModels(pathsArr, filename,data='study1',transformation=False,n_components=0.95):\n",
    "    # #create models\n",
    "    \n",
    "    np.random.seed(32)\n",
    "    #linear regression\n",
    "    logging.info('********Applying Linear Regression****************')\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "#     fit_intercept_space=[True,False]\n",
    "#     normalize_space=[True,False]\n",
    "    fit_intercept_space=[True]\n",
    "    param_grid={'fit_intercept':fit_intercept_space,\n",
    "#                 'normalize':normalize_space\n",
    "               }\n",
    "    regr= LinearRegression()\n",
    "    results_regr,predictions_regr= perform_evaluation(pathsArr,regr,param_grid,data=data,transformation=transformation,n_components=n_components)\n",
    "#     print(results_regr)\n",
    "\n",
    "    ## lasso regression\n",
    "    logging.info('********Applying Lasso Regression****************')\n",
    "    from sklearn.linear_model import Lasso\n",
    "    alpha_space = np.logspace(0, 1, 100)\n",
    "#     alpha_space = [0.001,0.01,0.1,1.0,2,3]\n",
    "    param_grid={'alpha':alpha_space}\n",
    "    lasso = Lasso(random_state=32)\n",
    "    results_lasso,predictions_lasso = perform_evaluation(pathsArr,lasso,param_grid,data=data,\n",
    "                                                        transformation=transformation,n_components=n_components)\n",
    "    \n",
    "\n",
    "\n",
    "    ## elastic net \n",
    "    logging.info('********Applying Elastic Net Regression****************')\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    alpha_space = np.logspace(0, 2 , 50)\n",
    "    param_grid={'alpha':alpha_space}\n",
    "    enet = ElasticNet(random_state=32)\n",
    "    results_enet,predictions_enet = perform_evaluation(pathsArr,enet,param_grid,data=data,transformation=transformation,n_components=n_components)\n",
    "\n",
    "    # ##create models\n",
    "    np.random.seed(19)\n",
    "    # support vector machines\n",
    "    logging.info('********Applying Support vector machine****************')\n",
    "    from sklearn.svm import SVR\n",
    "    C_space=np.logspace(-1,1,10)\n",
    "#     C_space = np.logspace(-2, 10, 5)\n",
    "    epsilon_space= np.logspace(-1,0,10)\n",
    "#     epsilon_space=np.logspace(-1,2,5)\n",
    "    gamma_space = np.logspace(-3, -2, 10)\n",
    "#     gamma_space='scale'\n",
    "    param_grid={'C':C_space,'epsilon':epsilon_space,'gamma':gamma_space}\n",
    "    svr = SVR(kernel = 'rbf')\n",
    "    results_svm,predictions_svm = perform_evaluation(pathsArr,svr,param_grid,method='random',data=data,transformation=transformation,n_components=n_components)\n",
    "\n",
    "\n",
    "#     # random forest\n",
    "#     logging.info('********Applying Random Forest****************')\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "#     n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "# #     n_estimators=[500,1000]\n",
    "#     max_depth = [int(x) for x in np.linspace(10, 20, num = 11)]\n",
    "#     min_samples_split = [2, 5, 10,15]\n",
    "#     min_samples_leaf = [5,10,50,100,200]\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "\n",
    "    max_depth = [int(x) for x in np.linspace(1, 5, num = 5)]\n",
    "\n",
    "    min_samples_split = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "    min_samples_leaf = [int(x) for x in np.linspace(10, 60, num = 20)]\n",
    "    bootstrap = [True, False]\n",
    "#     max_features=['sqrt']\n",
    "    max_features=['auto','sqrt']\n",
    "    param_grid={'n_estimators': n_estimators,\n",
    "                    'max_depth': max_depth,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "#                     'bootstrap': bootstrap,\n",
    "                    'max_features':max_features\n",
    "                   }   \n",
    "    rf = RandomForestRegressor(random_state=32)\n",
    "    results_rf,predictions_rf= perform_evaluation(pathsArr,rf,param_grid,method='random',data=data,transformation=transformation,n_components=n_components)\n",
    "\n",
    "    #Linear regression using stochastic gradient descent\n",
    "    logging.info('********Applying Linear regression with stochastic gradient descent****************')\n",
    "    from sklearn.linear_model import SGDRegressor\n",
    "    param_grid={#'max_iter':[100,500,1000],\n",
    "                'max_iter':[50,100],\n",
    "                'penalty':[None],\n",
    "                'eta0':[0.01,0.1,0.5]\n",
    "                   }\n",
    "    sgd_reg = SGDRegressor(random_state=32)\n",
    "    results_sgd,predictions_sgd = perform_evaluation(pathsArr,sgd_reg,param_grid,data=data,transformation=transformation,n_components=n_components)\n",
    "#     results_sgd\n",
    "\n",
    "#     # MARS\n",
    "    np.random.seed(20)\n",
    "    logging.info('********Applying MARS****************')\n",
    "    from pyearth import Earth\n",
    "    max_degree_space=[1]\n",
    "    #penalty_space=[3.0,6.0]\n",
    "   # minspan_alpha = np.linspace(0, 0.5, num = 10)\n",
    "    penalty_space=np.logspace(-1,1,20)\n",
    "    minspan_alpha=np.logspace(-3,1,20)\n",
    "    max_terms=[10,20,25]\n",
    "#     max_terms=np.linspace(25,30,num=5)\n",
    "    endspan_alpha = [0.05]\n",
    "    # # endspan_alpha= np.linspace(0, 1.0, num = 10)\n",
    "    # # endspan=[5]\n",
    "    param_grid={'max_degree':max_degree_space,\n",
    "        'penalty':penalty_space,\n",
    "             #  'minspan_alpha':minspan_alpha,\n",
    "        #'endspan_alpha':endspan_alpha,\n",
    "                'use_fast':[True],\n",
    "        'max_terms':max_terms\n",
    "               }\n",
    "    mars= Earth()\n",
    "    results_mars,predictions_mars= perform_evaluation(pathsArr,mars,param_grid,method='grid',data=data,transformation=transformation,n_components=n_components)\n",
    "#     results_mars\n",
    "    \n",
    "    def createTable(results,name):\n",
    "        '''Creates the final table'''\n",
    "        df= pd.concat([pd.DataFrame(results.get('r2_test')).T,\n",
    "        pd.DataFrame(results.get('r2_train')).T,\n",
    "                  pd.DataFrame(results.get('r2_validation')).T,\n",
    "        pd.DataFrame(results.get('rmse_test')).T,\n",
    "                  pd.DataFrame(results.get('rmse_train')).T,\n",
    "        pd.DataFrame(results.get('rmse_validation')).T,\n",
    "                  pd.DataFrame(results.get('std_validation')).T,\n",
    "                     pd.DataFrame(results.get('adjusted_r2_val')).T,\n",
    "                       pd.DataFrame(results.get('mae_train')).T,\n",
    "                      pd.DataFrame(results.get('mae_validation')).T,\n",
    "                      pd.DataFrame(results.get('mae_test')).T,\n",
    "                      pd.DataFrame(results.get('aic_validation')).T,\n",
    "                      pd.DataFrame(results.get('aic_test')).T,\n",
    "                      pd.DataFrame(results.get('bic_validation')).T,\n",
    "                      pd.DataFrame(results.get('bic_test')).T,\n",
    "                      pd.DataFrame(results.get('mape_validation')).T,\n",
    "                      pd.DataFrame(results.get('mape_test')).T],axis=1)\n",
    "        \n",
    "        df.columns=['R2(Test)','R2(Train)','R2(Validation)',\n",
    "                    'RMSE(Test)','RMSE(Train)','RMSE(Validation)',\n",
    "                    'StandardError(Validation)',\n",
    "                    'Adjusted R2(Validation)',\n",
    "                    'MAE(Train)','MAE(Validation)','MAE(Test)',\n",
    "                    'AIC(Validation)','AIC(Test)','BIC(Validation)','BIC(Test)',\n",
    "                   'MAPE(Validation)','MAPE(Test)']\n",
    "        df['Target']=df.index\n",
    "        df['Algorithm']=name\n",
    "        df= df.reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    df_sgd=createTable(results_sgd,name='Linear Regression SGD')\n",
    "    df_lasso=createTable(results_lasso,name='Lasso Regression')\n",
    "    df_enet=createTable(results_enet,name='Elastic Net')\n",
    "    df_svm=createTable(results_svm,name='SVM')\n",
    "    df_rf=createTable(results_rf,name='Random Forest')\n",
    "    df_mars=createTable(results_mars,name='MARS')\n",
    "    df_lr=createTable(results_regr,name='Linear Regression')\n",
    "    \n",
    "#     pd.concat([\n",
    "#         df_rf,df_svm,df_sgd,\n",
    "#         df_lr,\n",
    "#         df_lasso,\n",
    "#         df_enet,df_mars\n",
    "#     ]).to_csv(filename,index=False)\n",
    "    \n",
    "    del df_sgd,df_lasso,df_enet,df_svm,df_rf,df_mars\n",
    "    \n",
    "    def createPredictionsTable(predictions):\n",
    "        pq= pd.DataFrame(predictions.get('PQ'))\n",
    "        pq.rename(index=str, columns={\"Original\": \"Original_PQ\", \"Prediction\": \"Prediction_PQ\",'Residuals':'Residuals_PQ'}, inplace=True)\n",
    "        att=pd.DataFrame(predictions.get('ATT'))\n",
    "        att.rename(index=str, columns={\"Original\": \"Original_ATT\", \"Prediction\": \"Prediction_ATT\",'Residuals':'Residuals_ATT'},inplace=True)\n",
    "        df = pd.concat([pq,att],axis=1)\n",
    "        return df\n",
    "    \n",
    "    df_sgd=createPredictionsTable(predictions_sgd)\n",
    "    df_lasso=createPredictionsTable(predictions_lasso)\n",
    "    df_enet=createPredictionsTable(predictions_enet)\n",
    "    df_svm=createPredictionsTable(predictions_svm)\n",
    "    df_rf=createPredictionsTable(predictions_rf)\n",
    "    df_mars=createPredictionsTable(predictions_mars)\n",
    "    df_lr=createPredictionsTable(predictions_regr)\n",
    "    \n",
    "#     print(df_lasso)\n",
    "    if transformation==False:\n",
    "        filename=str(data)+'_PCA_alltargets_mahalanobis_'+str(n_components)+'_predictions_unseen.xlsx'\n",
    "    else:\n",
    "        filename=str(data)+'_PCA_alltargets_mahalanobis_transformed_'+str(n_components)+'_predictions_unseen.xlsx'\n",
    "    \n",
    "    with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
    "        df_sgd.to_excel(writer, sheet_name='Linear Regression SGD')\n",
    "        df_lasso.to_excel(writer, sheet_name='Lasso Regression')\n",
    "        df_enet.to_excel(writer, sheet_name='Elastic Net')\n",
    "        df_svm.to_excel(writer, sheet_name='SVM')\n",
    "        df_rf.to_excel(writer, sheet_name='Random Forest')\n",
    "        df_mars.to_excel(writer, sheet_name='MARS')\n",
    "        df_lr.to_excel(writer, sheet_name='LR')\n",
    "    \n",
    "    print('File saved successfully')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for checking the function\n",
    "# # uncomment it when you want\n",
    "\n",
    "# pathsArr=['../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "# transformation=False\n",
    "# n_components=0.95\n",
    "# data='study1'\n",
    "# from sklearn.linear_model import Lasso\n",
    "# alpha_space = np.logspace(0, 1, 100)\n",
    "# #     alpha_space = [0.001,0.01,0.1,1.0,2,3]\n",
    "# param_grid={'alpha':alpha_space}\n",
    "# lasso = Lasso(random_state=32)\n",
    "# results_lasso,predictions_lasso = perform_evaluation(pathsArr,lasso,param_grid,data=data,\n",
    "#                                                         transformation=transformation,n_components=n_components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study2 original and test on Study1 Original\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'fit_intercept': True}\n",
      "RMSE: 1.07\n",
      "R2(Validation): 0.51 (+/- 0.12)\n",
      "R2(Train): 0.63 (+/- 0.01)\n",
      "MAE(Validation): 0.86 (+/- 0.12)\n",
      "MAE(Train): 0.76 (+/- 0.01)\n",
      "Performance(R2):0.51\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):0.09 | RMSE:1.37 | MAE:1.05 | AIC:203.08 | MAPE:35.39\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'fit_intercept': True}\n",
      "RMSE: 1.14\n",
      "R2(Validation): 0.32 (+/- 0.14)\n",
      "R2(Train): 0.52 (+/- 0.01)\n",
      "MAE(Validation): 0.91 (+/- 0.13)\n",
      "MAE(Train): 0.78 (+/- 0.01)\n",
      "Performance(R2):0.32\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-0.20 | RMSE:1.54 | MAE:1.27 | AIC:246.33 | MAPE:48.89\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'alpha': 1.0}\n",
      "RMSE: 1.23\n",
      "R2(Validation): 0.35 (+/- 0.12)\n",
      "R2(Train): 0.38 (+/- 0.02)\n",
      "MAE(Validation): 1.02 (+/- 0.10)\n",
      "MAE(Train): 1.01 (+/- 0.01)\n",
      "Performance(R2):0.35\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-1.12 | RMSE:2.08 | MAE:1.65 | AIC:359.17 | MAPE:58.48\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'alpha': 1.0}\n",
      "RMSE: 1.20\n",
      "R2(Validation): 0.25 (+/- 0.07)\n",
      "R2(Train): 0.27 (+/- 0.01)\n",
      "MAE(Validation): 0.97 (+/- 0.10)\n",
      "MAE(Train): 0.96 (+/- 0.01)\n",
      "Performance(R2):0.25\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-1.10 | RMSE:2.03 | MAE:1.69 | AIC:350.00 | MAPE:68.11\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'alpha': 1.0}\n",
      "RMSE: 1.18\n",
      "R2(Validation): 0.41 (+/- 0.12)\n",
      "R2(Train): 0.44 (+/- 0.01)\n",
      "MAE(Validation): 0.96 (+/- 0.10)\n",
      "MAE(Train): 0.95 (+/- 0.01)\n",
      "Performance(R2):0.41\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-1.09 | RMSE:2.07 | MAE:1.67 | AIC:357.16 | MAPE:57.93\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'alpha': 1.0}\n",
      "RMSE: 1.14\n",
      "R2(Validation): 0.32 (+/- 0.06)\n",
      "R2(Train): 0.35 (+/- 0.01)\n",
      "MAE(Validation): 0.93 (+/- 0.10)\n",
      "MAE(Train): 0.92 (+/- 0.01)\n",
      "Performance(R2):0.32\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-1.10 | RMSE:2.03 | MAE:1.71 | AIC:349.77 | MAPE:67.84\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 0.005994842503189409, 'epsilon': 0.774263682681127, 'C': 1.291549665014884}\n",
      "RMSE: 1.01\n",
      "R2(Validation): 0.56 (+/- 0.09)\n",
      "R2(Train): 0.70 (+/- 0.01)\n",
      "MAE(Validation): 0.81 (+/- 0.12)\n",
      "MAE(Train): 0.70 (+/- 0.01)\n",
      "Performance(R2):0.56\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-0.13 | RMSE:1.53 | MAE:1.27 | AIC:243.16 | MAPE:36.77\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 0.0016681005372000592, 'epsilon': 0.5994842503189409, 'C': 1.291549665014884}\n",
      "RMSE: 1.07\n",
      "R2(Validation): 0.40 (+/- 0.08)\n",
      "R2(Train): 0.51 (+/- 0.01)\n",
      "MAE(Validation): 0.87 (+/- 0.11)\n",
      "MAE(Train): 0.79 (+/- 0.01)\n",
      "Performance(R2):0.40\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):0.00 | RMSE:1.40 | MAE:1.14 | AIC:211.52 | MAPE:44.54\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   54.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 90, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 3}\n",
      "RMSE: 1.10\n",
      "R2(Validation): 0.49 (+/- 0.10)\n",
      "R2(Train): 0.63 (+/- 0.01)\n",
      "MAE(Validation): 0.87 (+/- 0.11)\n",
      "MAE(Train): 0.75 (+/- 0.01)\n",
      "Performance(R2):0.49\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-0.18 | RMSE:1.55 | MAE:1.30 | AIC:250.10 | MAPE:36.73\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 90, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 3}\n",
      "RMSE: 1.13\n",
      "R2(Validation): 0.34 (+/- 0.09)\n",
      "R2(Train): 0.52 (+/- 0.01)\n",
      "MAE(Validation): 0.90 (+/- 0.12)\n",
      "MAE(Train): 0.78 (+/- 0.01)\n",
      "Performance(R2):0.34\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-0.18 | RMSE:1.52 | MAE:1.28 | AIC:242.12 | MAPE:41.61\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'eta0': 0.01, 'max_iter': 50, 'penalty': None}\n",
      "RMSE: 1.08\n",
      "R2(Validation): 0.50 (+/- 0.12)\n",
      "R2(Train): 0.63 (+/- 0.01)\n",
      "MAE(Validation): 0.87 (+/- 0.12)\n",
      "MAE(Train): 0.76 (+/- 0.02)\n",
      "Performance(R2):0.50\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):0.12 | RMSE:1.34 | MAE:1.03 | AIC:194.96 | MAPE:33.85\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'eta0': 0.01, 'max_iter': 50, 'penalty': None}\n",
      "RMSE: 1.17\n",
      "R2(Validation): 0.30 (+/- 0.14)\n",
      "R2(Train): 0.50 (+/- 0.01)\n",
      "MAE(Validation): 0.92 (+/- 0.14)\n",
      "MAE(Train): 0.80 (+/- 0.02)\n",
      "Performance(R2):0.30\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-0.03 | RMSE:1.42 | MAE:1.15 | AIC:217.06 | MAPE:44.51\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Prediction for PQ\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n",
      "Best params: {'max_degree': 1, 'max_terms': 20, 'penalty': 3.79269019073225, 'use_fast': True}\n",
      "RMSE: 1.08\n",
      "R2(Validation): 0.51 (+/- 0.11)\n",
      "R2(Train): 0.60 (+/- 0.01)\n",
      "MAE(Validation): 0.86 (+/- 0.14)\n",
      "MAE(Train): 0.78 (+/- 0.02)\n",
      "Performance(R2):0.51\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):-0.40 | RMSE:1.69 | MAE:1.41 | AIC:282.28 | MAPE:38.58\n",
      "****************************************************************************************************\n",
      "Prediction for ATT\n",
      "../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (587, 193)\n",
      "(587, 181)\n",
      "columns thrown away because they have 0 variance: Index([], dtype='object')\n",
      "False\n",
      "['swipe_length.x_mean', 'swipe_length.y_mean', 'button_touch_y_location_mean', 'target_touch_x_location_mean', 'target_touch_y_location_mean', 'x_location.release_mean', 'x_location.down_median', 'y_location.down_median', 'swipe_length_median', 'swipe_length.x_median', 'swipe_length.y_median', 'button_touch_x_location_median', 'button_touch_y_location_median', 'target_touch_x_location_median', 'target_touch_y_location_median', 'x_location.release_median', 'y_location.release_median', 'button_touch_x_location_skew', 'button_touch_y_location_skew', 'swipe_length.y_skew', 'y_location.down_skew', 'touch.duration_kurt', 'swipe_length.x_kurt', 'button_touch_y_location_kurt', 'target_touch_y_location_kurt', 'time_between_touches_kurt', 'y_location.release_kurt', 'difference.touch_buttonCenter_x_kurt', 'difference.touch_buttonCenter_y_kurt', 'touchAccuracy_x_kurt', 'touchAccuracy_y_kurt', 'button_touch_x_location_quantile', 'button_touch_y_location_quantile', 'difference.touch_buttonCenter_x_quantile', 'difference.touch_buttonCenter_y_quantile', 'swipe_length_quantile', 'swipe_length.x_quantile', 'swipe_length.y_quantile', 'target_touch_x_location_quantile', 'target_touch_y_location_quantile', 'time_between_touches_quantile', 'touch.duration_quantile', 'touchAccuracy_quantile', 'touchAccuracy_x_quantile', 'touchAccuracy_y_quantile', 'x_location.down_quantile', 'x_location.release_quantile', 'y_location.down_quantile', 'y_location.release_quantile', 'touch.duration_std', 'button_touch_x_location_std', 'button_touch_y_location_std', 'difference.touch_buttonCenter_x_std', 'difference.touch_buttonCenter_y_std', 'button_touch_x_location_mad', 'button_touch_y_location_mad', 'difference.touch_buttonCenter_x_mad', 'difference.touch_buttonCenter_y_mad', 'swipe_length_mad', 'swipe_length.x_mad', 'swipe_length.y_mad', 'target_touch_x_location_mad', 'target_touch_y_location_mad', 'time_between_touches_mad', 'touch.duration_mad', 'touchAccuracy_mad', 'touchAccuracy_x_mad', 'touchAccuracy_y_mad', 'x_location.down_mad', 'x_location.release_mad', 'y_location.down_mad', 'y_location.release_mad', 'swipe_length.x_max', 'button_touch_x_location_max', 'button_touch_y_location_max', 'target_touch_y_location_max', 'difference.touch_buttonCenter_x_max', 'difference.touch_buttonCenter_y_max', 'swipe_length.y_min', 'target_touch_y_location_min', 'y_location.release_min', 'hit_rate']\n",
      "Shape of the data after removing 0 variance highly correlated data: (587, 99)\n",
      "Reading the file from:  ../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv\n",
      "The shape of the data  currently:  (186, 191)\n",
      "Shape of the data after removing 0 variance highly correlated data: (186, 99)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "number of principal components: 43\n",
      "shape of training data  (410, 43)\n",
      "shape of test data (186, 43)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_degree': 1, 'max_terms': 10, 'penalty': 7.847599703514611, 'use_fast': True}\n",
      "RMSE: 1.06\n",
      "R2(Validation): 0.42 (+/- 0.10)\n",
      "R2(Train): 0.45 (+/- 0.01)\n",
      "MAE(Validation): 0.86 (+/- 0.12)\n",
      "MAE(Train): 0.84 (+/- 0.01)\n",
      "Performance(R2):0.42\n",
      "Peforming predictions on unseen data\n",
      "Performance(R2):0.04 | RMSE:1.37 | MAE:1.13 | AIC:203.64 | MAPE:40.55\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "File saved successfully\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on study1 data and test on study2 on original distribution with 95% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv',\n",
    "        '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "#     path=['../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv',\n",
    "#         '../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_0.95PC.csv'\n",
    "    runAllModels(path,filename,data='study2',transformation=False,n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for PQ\n",
      "/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n",
      "Reading the file from:  /mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-07f203b9e871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n\u001b[0;32m      5\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Tables/PCA_alltargets_mahalanobis_0.80PC.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mrunAllModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'study2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-c37d99f0a1ec>\u001b[0m in \u001b[0;36mrunAllModels\u001b[1;34m(pathsArr, filename, data, transformation, n_components)\u001b[0m\n\u001b[0;32m     13\u001b[0m                }\n\u001b[0;32m     14\u001b[0m     \u001b[0mregr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mresults_regr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions_regr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mperform_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathsArr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#     print(results_regr)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-0af65fc296b5>\u001b[0m in \u001b[0;36mperform_evaluation\u001b[1;34m(pathsArr, model, param_grid, method, data, transformation, n_components)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpathsArr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mpersonality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloadDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpersonality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mzero_var_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ee174279e33d>\u001b[0m in \u001b[0;36mloadDataset\u001b[1;34m(data, path, target, app)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'study1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../datasets/files_generated/UX/study1_features_data.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PQ'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Spell'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     if data== 'study1':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadDataFromCsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m#     if data=='study2':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         df = readDataFromCsv(path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ee174279e33d>\u001b[0m in \u001b[0;36mreadDataFromCsv\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Reading the file from: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# evaluate model on study1 data and test on study2 on original distribution with 80% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv',\n",
    "        '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_0.80PC.csv'\n",
    "    runAllModels(path,filename,data='study2',transformation=False,n_components=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on study1 data and test on study2 on original distribution with 3 PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis.csv',\n",
    "        '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_3PC.csv'\n",
    "    runAllModels(path,filename,data='study2',transformation=False,n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study2 transformation and test on Study1 transformation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on transformed distributions of study1 data and test on study2 with 95% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "        '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "#     path=['../../../datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "#          '../../../datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_transformed_0.95PC.csv'\n",
    "    runAllModels(path,filename,data='study2',transformation=True,n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on transformed distributions of study1 data and test on study2 with 80% variance explained PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "        '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_transformed_0.80PC.csv'\n",
    "    runAllModels(path,filename,data='study2',transformation=True,n_components=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on transformed distributions of study1 data and test on study2 with 3PC\n",
    "if __name__=='__main__':\n",
    "    path=['/mnt/vdb1/datasets/files_generated/UX/study2_features_data_out_mahalanobis_transformedDistributions.csv',\n",
    "        '/mnt/vdb1/datasets/files_generated/UX/study1_features_data_out_mahalanobis_transformedDistributions.csv']\n",
    "    filename='Tables/PCA_alltargets_mahalanobis_transformed_3PC.csv'\n",
    "    runAllModels(path,filename,data='study2',transformation=True,n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
